{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3c8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60443dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ad83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv(\"Songs Dataset/songdata.csv\")\n",
    "songs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ede6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(songs['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b562736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"look at her face it's a wonderful face and it means something special to me\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lower case, strip and punc\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    pattern = \"[A-Za-z0-9']+\"\n",
    "    return ' '.join(re.findall(pattern, text)).lower()\n",
    "    \n",
    "clean_text(\"Look at her face, it's a wonderful face  \\nAnd it means something special to me  \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aa61cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"take it easy with me please touch me gently like a summer evening breeze take your time make it slow andante andante just let the feeling grow make your fingers soft and light let your body be the velvet of the night touch my soul you know how andante andante go slowly with me now i'm your music i am your music and i am your song i'm your song i am your music and i am your song play me time and time again and make me strong play me again 'cause you're making me strong make me sing make me sound you make me sing and you make me andante andante tread lightly on my ground andante andante oh please don't let me down there's a shimmer in your eyes like the feeling of a thousand butterflies please don't talk go on play andante andante and let me float away i'm your music i am your music and i am your song i'm your song i am your music and i am your song play me time and time again and make me strong play me again 'cause you're making me strong make me sing make me sound you make me sing and you make me andante andante tread lightly on my ground andante andante oh please don't let me down make me sing make me sound you make me sing and you make me andante andante tread lightly on my ground andante andante oh please don't let me down andante andante oh please don't let me down\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs['clean'] = songs['text'].apply(lambda x : clean_text(x))\n",
    "songs['clean'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83e64467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"look at her face it's a wonderful face and it means something special to me look at the way that she smiles when she sees me how lucky can one fellow be she's just my kind of girl she makes me feel fine who could ever believe that she could be mine she's just my kind of girl without her i'm blue and if she ever leaves me what could i do what could i do and when we go for a walk in the park and she holds me and squeezes my hand we'll go on walking for hours and talking about all the things that we plan she's just my kind of girl she makes me feel fine who could ever believe that she could be mine she's just my kind of girl without her i'm blue and if she ever leaves me what could i do what could i do\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics = songs['clean']\n",
    "sample = lyrics[0:2]\n",
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75e6daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "MAX_LENGTH = 250\n",
    "EMBEDDING_DIM = 50\n",
    "OOV_TOKEN = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d2c140a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE,\n",
    "                      oov_token=OOV_TOKEN)\n",
    "tokenizer.fit_on_texts(lyrics)\n",
    "#sequences = tokenizer.texts_to_sequences(lyrics)\n",
    "#padded_sequences = pad_sequences(sequences, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "80273ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Of Training Examples for two songs (411, 250)\n"
     ]
    }
   ],
   "source": [
    "def create_XyPairs(songs, tokenizer, MAX_LENGTH):\n",
    "    #X and y pairs\n",
    "    X=[]\n",
    "    y=[]\n",
    "    \n",
    "    for song in songs:\n",
    "        #print('------------------')\n",
    "        words = song.split()\n",
    "        for word_index in range(1, len(words)):\n",
    "            sentence = [' '.join(words[:word_index])]\n",
    "            sequence = tokenizer.texts_to_sequences(sentence)\n",
    "            padded_sequences = pad_sequences(sequence, maxlen=MAX_LENGTH)\n",
    "            #print(f'X:{sentence}')                # ~~> Actual Word\n",
    "            #print(f'X:{padded_sequences}')        # ~~> Padded Tokenized \n",
    "            X.append(padded_sequences)\n",
    "            #print(f'y:{[words[word_index]]}')   # ~~> Actual Word\n",
    "            #print(f'y:{tokenizer.texts_to_sequences([words[word_index]])}')    # ~~> Tokenized word\n",
    "            y.append(tokenizer.texts_to_sequences([words[word_index]]))\n",
    "                   \n",
    "\n",
    "    X = np.array(X).reshape(-1, MAX_LENGTH)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    y=to_categorical(y)\n",
    "    return X,y\n",
    "            \n",
    "print('Shape Of Training Examples for two songs', create_XyPairs(sample, tokenizer, MAX_LENGTH)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4b5e6d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Of Training Examples for 50 song (12432, 250)\n",
      "Shape Of Training Labels for 50 song (12432, 4999)\n"
     ]
    }
   ],
   "source": [
    "#for 50 song\n",
    "sample_50 = songs['clean'][:50]\n",
    "\n",
    "X,y = create_XyPairs(sample_50, tokenizer, MAX_LENGTH)\n",
    "print('Shape Of Training Examples for 50 song', X.shape)\n",
    "print('Shape Of Training Labels for 50 song'  , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a5f56e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "12432/12432 [==============================] - 148s 12ms/step - loss: 6.1454 - accuracy: 0.0413\n",
      "Epoch 2/2\n",
      "12432/12432 [==============================] - 142s 11ms/step - loss: 5.5612 - accuracy: 0.0543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22d0bb9cb70>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Embedding(VOCAB_SIZE, EMBEDDING_DIM,\n",
    "                  input_shape=([MAX_LENGTH])),\n",
    "        Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True)),\n",
    "        Bidirectional(LSTM(EMBEDDING_DIM)),\n",
    "        Dense(VOCAB_SIZE-1, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X,y, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f0b7699c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12432/12432 [==============================] - 133s 11ms/step - loss: 5.3880 - accuracy: 0.0640\n",
      "Epoch 2/10\n",
      "12432/12432 [==============================] - 133s 11ms/step - loss: 5.2369 - accuracy: 0.0816\n",
      "Epoch 3/10\n",
      "12432/12432 [==============================] - 134s 11ms/step - loss: 5.1045 - accuracy: 0.0956\n",
      "Epoch 4/10\n",
      "12432/12432 [==============================] - 134s 11ms/step - loss: 4.9839 - accuracy: 0.1114\n",
      "Epoch 5/10\n",
      "12432/12432 [==============================] - 134s 11ms/step - loss: 4.8435 - accuracy: 0.1238\n",
      "Epoch 6/10\n",
      "12432/12432 [==============================] - 135s 11ms/step - loss: 4.7429 - accuracy: 0.1379\n",
      "Epoch 7/10\n",
      "12432/12432 [==============================] - 135s 11ms/step - loss: 4.6385 - accuracy: 0.1424\n",
      "Epoch 8/10\n",
      "12432/12432 [==============================] - 137s 11ms/step - loss: 4.5541 - accuracy: 0.1501\n",
      "Epoch 9/10\n",
      "12432/12432 [==============================] - 138s 11ms/step - loss: 4.4645 - accuracy: 0.1569\n",
      "Epoch 10/10\n",
      "12432/12432 [==============================] - 142s 11ms/step - loss: 4.3806 - accuracy: 0.1637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22d1eda6b70>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1a26b7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "12432/12432 [==============================] - 133s 11ms/step - loss: 4.2234 - accuracy: 0.1815\n",
      "Epoch 2/75\n",
      "12432/12432 [==============================] - 138s 11ms/step - loss: 4.1505 - accuracy: 0.1910\n",
      "Epoch 3/75\n",
      "12432/12432 [==============================] - 136s 11ms/step - loss: 4.0804 - accuracy: 0.2006\n",
      "Epoch 4/75\n",
      "12432/12432 [==============================] - 148s 12ms/step - loss: 4.0155 - accuracy: 0.2066\n",
      "Epoch 5/75\n",
      "12432/12432 [==============================] - 150s 12ms/step - loss: 3.9457 - accuracy: 0.2132\n",
      "Epoch 6/75\n",
      "12432/12432 [==============================] - 145s 12ms/step - loss: 3.8837 - accuracy: 0.2214\n",
      "Epoch 7/75\n",
      "12432/12432 [==============================] - 145s 12ms/step - loss: 3.8081 - accuracy: 0.2324\n",
      "Epoch 8/75\n",
      "12432/12432 [==============================] - 146s 12ms/step - loss: 3.7268 - accuracy: 0.2425\n",
      "Epoch 9/75\n",
      "12432/12432 [==============================] - 146s 12ms/step - loss: 3.6545 - accuracy: 0.2557\n",
      "Epoch 10/75\n",
      "12432/12432 [==============================] - 145s 12ms/step - loss: 3.5794 - accuracy: 0.2641\n",
      "Epoch 11/75\n",
      "12432/12432 [==============================] - 144s 12ms/step - loss: 3.5240 - accuracy: 0.2662\n",
      "Epoch 12/75\n",
      "12432/12432 [==============================] - 139s 11ms/step - loss: 3.4488 - accuracy: 0.2836\n",
      "Epoch 13/75\n",
      "12432/12432 [==============================] - 143s 11ms/step - loss: 3.3778 - accuracy: 0.2917\n",
      "Epoch 14/75\n",
      "12432/12432 [==============================] - 143s 12ms/step - loss: 3.3130 - accuracy: 0.3043\n",
      "Epoch 15/75\n",
      "12432/12432 [==============================] - 140s 11ms/step - loss: 3.2300 - accuracy: 0.3177\n",
      "Epoch 16/75\n",
      "12432/12432 [==============================] - 141s 11ms/step - loss: 3.1931 - accuracy: 0.3234\n",
      "Epoch 17/75\n",
      "12432/12432 [==============================] - 140s 11ms/step - loss: 3.1191 - accuracy: 0.3357\n",
      "Epoch 18/75\n",
      "12432/12432 [==============================] - 140s 11ms/step - loss: 3.0331 - accuracy: 0.3521\n",
      "Epoch 19/75\n",
      "12432/12432 [==============================] - 141s 11ms/step - loss: 3.1382 - accuracy: 0.3307\n",
      "Epoch 20/75\n",
      "12432/12432 [==============================] - 142s 11ms/step - loss: 2.9681 - accuracy: 0.3620\n",
      "Epoch 21/75\n",
      "12432/12432 [==============================] - 141s 11ms/step - loss: 2.8734 - accuracy: 0.3785\n",
      "Epoch 22/75\n",
      "12432/12432 [==============================] - 142s 11ms/step - loss: 2.8152 - accuracy: 0.3938\n",
      "Epoch 23/75\n",
      "12432/12432 [==============================] - 141s 11ms/step - loss: 2.7452 - accuracy: 0.4061\n",
      "Epoch 24/75\n",
      "12432/12432 [==============================] - 140s 11ms/step - loss: 2.6799 - accuracy: 0.4131\n",
      "Epoch 25/75\n",
      "12432/12432 [==============================] - 141s 11ms/step - loss: 2.6021 - accuracy: 0.4341\n",
      "Epoch 26/75\n",
      "12432/12432 [==============================] - 142s 11ms/step - loss: 2.5488 - accuracy: 0.4416\n",
      "Epoch 27/75\n",
      "12432/12432 [==============================] - 141s 11ms/step - loss: 2.5040 - accuracy: 0.4485\n",
      "Epoch 28/75\n",
      "12432/12432 [==============================] - 142s 11ms/step - loss: 2.4607 - accuracy: 0.4592\n",
      "Epoch 29/75\n",
      "12432/12432 [==============================] - 141s 11ms/step - loss: 2.3901 - accuracy: 0.4742\n",
      "Epoch 30/75\n",
      "12432/12432 [==============================] - 141s 11ms/step - loss: 2.3196 - accuracy: 0.4914\n",
      "Epoch 31/75\n",
      "12432/12432 [==============================] - 142s 11ms/step - loss: 2.2613 - accuracy: 0.5028\n",
      "Epoch 32/75\n",
      "12432/12432 [==============================] - 141s 11ms/step - loss: 2.2088 - accuracy: 0.5155\n",
      "Epoch 33/75\n",
      "12432/12432 [==============================] - 142s 11ms/step - loss: 2.2239 - accuracy: 0.5075\n",
      "Epoch 34/75\n",
      "12432/12432 [==============================] - 143s 11ms/step - loss: 2.1321 - accuracy: 0.5262\n",
      "Epoch 35/75\n",
      "12432/12432 [==============================] - 145s 12ms/step - loss: 2.1149 - accuracy: 0.5323\n",
      "Epoch 36/75\n",
      "12432/12432 [==============================] - 143s 11ms/step - loss: 2.0518 - accuracy: 0.5458\n",
      "Epoch 37/75\n",
      "12432/12432 [==============================] - 146s 12ms/step - loss: 1.9728 - accuracy: 0.5657\n",
      "Epoch 38/75\n",
      "12432/12432 [==============================] - 144s 12ms/step - loss: 1.9672 - accuracy: 0.5671\n",
      "Epoch 39/75\n",
      "12432/12432 [==============================] - 146s 12ms/step - loss: 1.9002 - accuracy: 0.5805\n",
      "Epoch 40/75\n",
      "12432/12432 [==============================] - 150s 12ms/step - loss: 1.9406 - accuracy: 0.5699\n",
      "Epoch 41/75\n",
      "12432/12432 [==============================] - 151s 12ms/step - loss: 1.8646 - accuracy: 0.5918\n",
      "Epoch 42/75\n",
      "12432/12432 [==============================] - 151s 12ms/step - loss: 1.8008 - accuracy: 0.6059\n",
      "Epoch 43/75\n",
      "12432/12432 [==============================] - 152s 12ms/step - loss: 1.7241 - accuracy: 0.6235\n",
      "Epoch 44/75\n",
      "12432/12432 [==============================] - 148s 12ms/step - loss: 1.6671 - accuracy: 0.6351\n",
      "Epoch 45/75\n",
      "12432/12432 [==============================] - 145s 12ms/step - loss: 1.6243 - accuracy: 0.6462\n",
      "Epoch 46/75\n",
      "12432/12432 [==============================] - 144s 12ms/step - loss: 1.5822 - accuracy: 0.6551\n",
      "Epoch 47/75\n",
      "12432/12432 [==============================] - 146s 12ms/step - loss: 1.5434 - accuracy: 0.6634\n",
      "Epoch 48/75\n",
      "12432/12432 [==============================] - 145s 12ms/step - loss: 1.5753 - accuracy: 0.6543\n",
      "Epoch 49/75\n",
      "12432/12432 [==============================] - 145s 12ms/step - loss: 1.5313 - accuracy: 0.6624\n",
      "Epoch 50/75\n",
      "12432/12432 [==============================] - 144s 12ms/step - loss: 1.4742 - accuracy: 0.6778\n",
      "Epoch 51/75\n",
      "12432/12432 [==============================] - 145s 12ms/step - loss: 1.4237 - accuracy: 0.6858\n",
      "Epoch 52/75\n",
      "12432/12432 [==============================] - 145s 12ms/step - loss: 1.3725 - accuracy: 0.6997\n",
      "Epoch 53/75\n",
      "12432/12432 [==============================] - 151s 12ms/step - loss: 1.3598 - accuracy: 0.7037\n",
      "Epoch 54/75\n",
      "12432/12432 [==============================] - 152s 12ms/step - loss: 1.3256 - accuracy: 0.7099\n",
      "Epoch 55/75\n",
      "12432/12432 [==============================] - 152s 12ms/step - loss: 1.3839 - accuracy: 0.6980\n",
      "Epoch 56/75\n",
      "12432/12432 [==============================] - 153s 12ms/step - loss: 1.3373 - accuracy: 0.7059\n",
      "Epoch 57/75\n",
      "12432/12432 [==============================] - 152s 12ms/step - loss: 1.2611 - accuracy: 0.7280\n",
      "Epoch 58/75\n",
      "12432/12432 [==============================] - 155s 12ms/step - loss: 1.4215 - accuracy: 0.6885\n",
      "Epoch 59/75\n",
      "12432/12432 [==============================] - 155s 12ms/step - loss: 1.2390 - accuracy: 0.7313\n",
      "Epoch 60/75\n",
      "12432/12432 [==============================] - 152s 12ms/step - loss: 1.1584 - accuracy: 0.7478\n",
      "Epoch 61/75\n",
      "12432/12432 [==============================] - 152s 12ms/step - loss: 1.5443 - accuracy: 0.6515\n",
      "Epoch 62/75\n",
      "12432/12432 [==============================] - 153s 12ms/step - loss: 1.3170 - accuracy: 0.7091\n",
      "Epoch 63/75\n",
      "12432/12432 [==============================] - 153s 12ms/step - loss: 1.2024 - accuracy: 0.7353\n",
      "Epoch 64/75\n",
      "12432/12432 [==============================] - 154s 12ms/step - loss: 1.1623 - accuracy: 0.7443\n",
      "Epoch 65/75\n",
      "12432/12432 [==============================] - 154s 12ms/step - loss: 1.1000 - accuracy: 0.7596\n",
      "Epoch 66/75\n",
      "12432/12432 [==============================] - 153s 12ms/step - loss: 1.0623 - accuracy: 0.7704\n",
      "Epoch 67/75\n",
      "12432/12432 [==============================] - 150s 12ms/step - loss: 1.0019 - accuracy: 0.7880\n",
      "Epoch 68/75\n",
      "12432/12432 [==============================] - 155s 12ms/step - loss: 0.9698 - accuracy: 0.7942\n",
      "Epoch 69/75\n",
      "12432/12432 [==============================] - 156s 13ms/step - loss: 1.2708 - accuracy: 0.7095\n",
      "Epoch 70/75\n",
      "12432/12432 [==============================] - 154s 12ms/step - loss: 1.1077 - accuracy: 0.7539\n",
      "Epoch 71/75\n",
      "12432/12432 [==============================] - 156s 13ms/step - loss: 1.0147 - accuracy: 0.7799\n",
      "Epoch 72/75\n",
      "12432/12432 [==============================] - 161s 13ms/step - loss: 0.9635 - accuracy: 0.7969\n",
      "Epoch 73/75\n",
      "12432/12432 [==============================] - 163s 13ms/step - loss: 0.9134 - accuracy: 0.8094\n",
      "Epoch 74/75\n",
      "12432/12432 [==============================] - 153s 12ms/step - loss: 0.9829 - accuracy: 0.7872\n",
      "Epoch 75/75\n",
      "12432/12432 [==============================] - 155s 12ms/step - loss: 0.9431 - accuracy: 0.7989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22d1ed8a780>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fc2e759f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(pad_sequences(tokenizer.texts_to_sequences([\"look at her\"]), maxlen=MAX_LENGTH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6f6de340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model, load_model\n",
    "\n",
    "save_model(model, 'text_gen.h5')\n",
    "model = load_model('text_gen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5fd04225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 6, 7, 8]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences([[5,6,7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "e122a4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you were supposed to sing you through me my plain in the summer story leaves movie through the start for i was so to sing to give out over ship'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_song(model, tokenizer, starter, sentence_long):\n",
    "    length = len(starter.split())\n",
    "    text = [starter]\n",
    "\n",
    "    for _ in range(length, sentence_long):\n",
    "        #print(text, ' is entering tokenizer')\n",
    "        sequence = tokenizer.texts_to_sequences(text)[0]\n",
    "        #print(sequence, ' is entering padding')\n",
    "        padded_sequences = pad_sequences([sequence], maxlen=MAX_LENGTH)\n",
    "        #print(padded_sequences, ' is entering model')\n",
    "        predictions = model.predict(padded_sequences)[0]\n",
    "        sampled = np.random.choice(list(range(len(predictions))), p=predictions)\n",
    "        #print(sampled, ' is predicted')\n",
    "        word = tokenizer.index_word[sampled]\n",
    "        #print(word, ' is predicted')\n",
    "        text = [text[0] + ' ' + word]\n",
    "        #print(text, ' is final text')\n",
    "        \n",
    "    return ' '.join(text)\n",
    "        \n",
    "\n",
    "    \n",
    "generate_song(model, tokenizer, 'you were supposed to', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edf43c6",
   "metadata": {},
   "source": [
    "# `YEAH WHATEVER` `MC-DODOELSAKKA \\ LIL DODOELSAKKA`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707f27b8",
   "metadata": {},
   "source": [
    "# `DODO BOOMIN WANTS SOME MORE` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538e4ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
